{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d6eff709",
      "metadata": {
        "id": "d6eff709"
      },
      "source": [
        "# Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04e5db71",
      "metadata": {
        "id": "04e5db71"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load from google drive online"
      ],
      "metadata": {
        "id": "_L9jPPUDpSJQ"
      },
      "id": "_L9jPPUDpSJQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set drive location as /mydrive\n",
        "!ln -s /content/drive/MyDrive/ /mydrive\n",
        "# See inside of /mdrive folder\n",
        "!ls /mydrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzQiO6GImWGC",
        "outputId": "34013ad0-92b8-407d-ec02-0c37deff3c45"
      },
      "id": "GzQiO6GImWGC",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/mydrive\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fa048722",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa048722",
        "outputId": "a8ec273f-869b-45d8-8e37-b3a32ef93ee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'a kind of saulty cocktail\", according to legend, with the word \"salty\" added at the end. It is also referred to as a \"spicy muddle\". Ingredients: 2 oz. Brandy, 0.75 oz. Lemon Juice, 0.25 oz. Simple Syrup, 0.25 oz. Peychauds Bitters. Directions: shake on ice and strain Garnish with Lemon twist. '}]\n"
          ]
        }
      ],
      "source": [
        "# load our model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained('./drive/MyDrive/20240331_saved model and tokenizer') # change into the private google drive path\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('./drive/MyDrive/20240331_saved model and tokenizer')\n",
        "\n",
        "# set pad_token of tokenizer as eos_token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# # create pipeline with our model and tokenizer\n",
        "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
        "\n",
        "# # test the function\n",
        "print(generator(\"a kind of saulty cocktail\", max_length=100))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load from local path"
      ],
      "metadata": {
        "id": "H2wpSR33qBEp"
      },
      "id": "H2wpSR33qBEp"
    },
    {
      "cell_type": "code",
      "source": [
        "# load our model and tokenizer\n",
        "model = GPT2LMHeadModel.from_pretrained('C:\\\\Users\\\\user_name\\\\Documents\\\\saved files(model and tokenizer)') # change into the local path\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('''local path''')\n",
        "\n",
        "# set pad_token of tokenizer as eos_token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# # create pipeline with our model and tokenizer\n",
        "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
        "\n",
        "# # test the function\n",
        "print(generator(\"a kind of saulty cocktail\", max_length=100))"
      ],
      "metadata": {
        "id": "tPY7vScDqFi8"
      },
      "id": "tPY7vScDqFi8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4d92f08f",
      "metadata": {
        "id": "4d92f08f"
      },
      "source": [
        "# Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "318978b9",
      "metadata": {
        "id": "318978b9"
      },
      "outputs": [],
      "source": [
        "from transformers import Conversation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test online(colab)"
      ],
      "metadata": {
        "id": "28oGoOm5pgVo"
      },
      "id": "28oGoOm5pgVo"
    },
    {
      "cell_type": "code",
      "source": [
        "# set padding_side='left'\n",
        "tokenizer.padding_side = \"left\"\n",
        "\n",
        "# Initialize pipeline 'chatbot'\n",
        "chatbot = pipeline('conversational', model=model, tokenizer=tokenizer)\n",
        "# 初始化对话\n",
        "conversation = Conversation(\"give me a recipe of cocktail?\")\n",
        "\n",
        "# 运行对话管道并获取模型的回复\n",
        "conversation = chatbot([conversation])\n",
        "print(conversation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMwzboa4nWMZ",
        "outputId": "346d8d8c-6b45-4edd-90cb-c3803f4c5c44"
      },
      "id": "mMwzboa4nWMZ",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation id: 69c887ba-e875-4672-89aa-3eba170d5eb2\n",
            "user: give me a recipe of cocktail?\n",
            "assistant: \n",
            "Yes please—our favorite variation on the Lemon Drop Cocktail is the Hammerhead. Yes, the Hammerhead is called a Lemon Drop Cocktail, but you can technically use any of the other flavors—it's all up to you. Here are a few variations:\n",
            "\n",
            "Get the recipe for Lousiana Hammerhead Here., 7 cl Rye, 3 cl Carpano Antica Syrup, 1 cl Fresh lemon juice. Pour all ingredients straight from the can into a mixing glass, and stir, until the ingredients settle. Strain into a chilled cocktail glass, and garnish with a lemon twist. Garnish with the lemon twist.. Directions:. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"please give me another cocktail recipe?\"\n",
        "conversation.add_user_input(user_input)\n",
        "conversation = chatbot([conversation])\n",
        "print(conversation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p12bbsb-oOSY",
        "outputId": "a6c086d4-597b-466a-c21e-5f3d8c25f6bd"
      },
      "id": "p12bbsb-oOSY",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation id: 69c887ba-e875-4672-89aa-3eba170d5eb2\n",
            "user: give me a recipe of cocktail?\n",
            "assistant: \n",
            "Yes please—our favorite variation on the Lemon Drop Cocktail is the Hammerhead. Yes, the Hammerhead is called a Lemon Drop Cocktail, but you can technically use any of the other flavors—it's all up to you. Here are a few variations:\n",
            "\n",
            "Get the recipe for Lousiana Hammerhead Here., 7 cl Rye, 3 cl Carpano Antica Syrup, 1 cl Fresh lemon juice. Pour all ingredients straight from the can into a mixing glass, and stir, until the ingredients settle. Strain into a chilled cocktail glass, and garnish with a lemon twist. Garnish with the lemon twist.. Directions:. \n",
            "user: please give me another cocktail recipe?\n",
            "assistant: ....And so, on the 10th of July, with both parties all together, the first in a long line of official British summertime cocktail days, have come the official cocktail of the summer, the Lime-Fuzztail. A Lime twist on the Gin and Orange Sour, but with a touch of orange zest.. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"please directively describe the recipe?\"\n",
        "conversation.add_user_input(user_input)\n",
        "conversation = chatbot([conversation])\n",
        "print(conversation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YObXvRqfoewD",
        "outputId": "126debbe-868a-4fff-b668-92c72d9ac46d"
      },
      "id": "YObXvRqfoewD",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation id: 69c887ba-e875-4672-89aa-3eba170d5eb2\n",
            "user: give me a recipe of cocktail?\n",
            "assistant: \n",
            "Yes please—our favorite variation on the Lemon Drop Cocktail is the Hammerhead. Yes, the Hammerhead is called a Lemon Drop Cocktail, but you can technically use any of the other flavors—it's all up to you. Here are a few variations:\n",
            "\n",
            "Get the recipe for Lousiana Hammerhead Here., 7 cl Rye, 3 cl Carpano Antica Syrup, 1 cl Fresh lemon juice. Pour all ingredients straight from the can into a mixing glass, and stir, until the ingredients settle. Strain into a chilled cocktail glass, and garnish with a lemon twist. Garnish with the lemon twist.. Directions:. \n",
            "user: please give me another cocktail recipe?\n",
            "assistant: ....And so, on the 10th of July, with both parties all together, the first in a long line of official British summertime cocktail days, have come the official cocktail of the summer, the Lime-Fuzztail. A Lime twist on the Gin and Orange Sour, but with a touch of orange zest.. \n",
            "user: please directively describe the recipe?\n",
            "assistant: \n",
            "user: please directively describe the recipe?\n",
            "assistant:  The only time many Irish have a chance at a classic vodka drink, is on Martin Place. One of its more quintessentially Irish origins, is in the Irish Tea Box cocktail, a potent concoction made with instant tea. In a modern cocktail, the tea is usually ground cinnamon or nutmeg to add subtle complexity, and the hot liquid is in a teak cask, to further add to the flavour enhancement. Both teapots are popular in the States, but are so hard to come by in Ireland. A teapot is a fine-textured glass teapot that retains water and is filled with teas that have been heated. The key to a good teapot is a carefully prepared drink, such as a blended Irish or British tea, with a high proportion of ginger, nutmeg and cinnamon in the drink. No two teapots are the same, yet a cup of heated tea is the ideal complement to a classic Irish or British whisky., In a teapot, the hot liquid is in a tawny glass. The mixture is sloshed in this manner over a long period of time., In a brisk drink, add a few drops of chilled club soda in the muddle. The carbonation created by the soda\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## define the chat function(run locally)"
      ],
      "metadata": {
        "id": "08dUG4LtpmDk"
      },
      "id": "08dUG4LtpmDk"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e7f6344f",
      "metadata": {
        "id": "e7f6344f"
      },
      "outputs": [],
      "source": [
        "# Initialize pipeline 'chatbot'\n",
        "chatbot = pipeline('conversational', model=model, tokenizer=tokenizer)\n",
        "\n",
        "i = 0\n",
        "\n",
        "def chat(user_input):\n",
        "  global i\n",
        "  global conversation\n",
        "  if i == 0:\n",
        "# Conversation objects initialized with a string will treat it as a user message\n",
        "    conversation = Conversation(user_input)\n",
        "# generate conversation by pipeline\n",
        "    conversation = chatbot(conversation)\n",
        "    i = i + 1\n",
        "  else:\n",
        "# add user input添加输入\n",
        "    conversation.add_user_input(user_input)\n",
        "# generate conversation生成对话\n",
        "    conversation = chatbot(conversation)\n",
        "    i = i + 1\n",
        "  return conversation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "770d8ff6",
      "metadata": {
        "id": "770d8ff6"
      },
      "source": [
        "# GUI window(run locally)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e52ebe70",
      "metadata": {
        "id": "e52ebe70"
      },
      "outputs": [],
      "source": [
        "import tkinter as tk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ec1c7ff6",
      "metadata": {
        "id": "ec1c7ff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "14c077db-2606-4271-d5d4-eb5cfb4dc5f6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TclError",
          "evalue": "no display name and no $DISPLAY environment variable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a84639817468>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# create the main window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cocktail Asistant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# label1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2297\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2298\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2299\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2300\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
          ]
        }
      ],
      "source": [
        "def commit_requirements():\n",
        "  global conversation\n",
        "  commands = entry.get()\n",
        "  conversation = chat(commands)\n",
        "#   recommendation = generator(commands, max_length=300)\n",
        "  label2.config(text=f\"{conversation}\")\n",
        "  label3.config(text=i)\n",
        "\n",
        "def restart():\n",
        "  global i\n",
        "  i = 0\n",
        "  label3.config(text=i)\n",
        "\n",
        "# create the main window\n",
        "root = tk.Tk()\n",
        "root.title(\"Cocktail Asistant\")\n",
        "# label1\n",
        "label1 = tk.Label(root, text=\"Welcome to Cocktail Asistant! Please write your command:\")\n",
        "label1.pack(pady=10)\n",
        "# entry widget\n",
        "entry = tk.Entry(root, width=40)\n",
        "entry.pack(pady=10)\n",
        "# button1\n",
        "button1 = tk.Button(root, text=\"commit\", command=commit_requirements)\n",
        "button1.pack(pady=10)\n",
        "# label2\n",
        "label2 = tk.Label(root, text=\"Here's my recommendation\", wraplength=400)\n",
        "label2.pack(pady=10)\n",
        "# button2\n",
        "button2 = tk.Button(root, text=\"restart\", command=restart)\n",
        "button2.pack(pady=10)\n",
        "# label3\n",
        "label3 = tk.Label(root, text=\"round number\", wraplength=400)\n",
        "label3.pack(pady=10)\n",
        "# start the event loop\n",
        "root.mainloop()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_L9jPPUDpSJQ",
        "H2wpSR33qBEp",
        "28oGoOm5pgVo",
        "08dUG4LtpmDk",
        "770d8ff6"
      ],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}